// Code generated by "core generate -add-types"; DO NOT EDIT.

package leabra

import (
	"cogentcore.org/core/types"
)

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActParams", IDName: "act-params", Doc: "leabra.ActParams contains all the activation computation params and functions\nfor basic Leabra, at the neuron level .\nThis is included in leabra.Layer to drive the computation.", Fields: []types.Field{{Name: "XX1", Doc: "Noisy X/X+1 rate code activation function parameters"}, {Name: "OptThresh", Doc: "optimization thresholds for faster processing"}, {Name: "Init", Doc: "initial values for key network state variables -- initialized at start of trial with InitActs or DecayActs"}, {Name: "Dt", Doc: "time and rate constants for temporal derivatives / updating of activation state"}, {Name: "Gbar", Doc: "maximal conductances levels for channels"}, {Name: "Erev", Doc: "reversal potentials for each channel"}, {Name: "Clamp", Doc: "how external inputs drive neural activations"}, {Name: "Noise", Doc: "how, where, when, and how much noise to add to activations"}, {Name: "VmRange", Doc: "range for Vm membrane potential -- by default"}, {Name: "KNa", Doc: "sodium-gated potassium channel adaptation parameters -- activates an inhibitory leak-like current as a function of neural activity (firing = Na influx) at three different time-scales (M-type = fast, Slick = medium, Slack = slow)"}, {Name: "ErevSubThr", Doc: "Erev - Act.Thr for each channel -- used in computing GeThrFromG among others"}, {Name: "ThrSubErev", Doc: "Act.Thr - Erev for each channel -- used in computing GeThrFromG among others"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.OptThreshParams", IDName: "opt-thresh-params", Doc: "OptThreshParams provides optimization thresholds for faster processing", Fields: []types.Field{{Name: "Send", Doc: "don't send activation when act <= send -- greatly speeds processing"}, {Name: "Delta", Doc: "don't send activation changes until they exceed this threshold: only for when LeabraNetwork::send_delta is on!"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActInitParams", IDName: "act-init-params", Doc: "ActInitParams are initial values for key network state variables.\nInitialized at start of trial with Init_Acts or DecayState.", Fields: []types.Field{{Name: "Decay", Doc: "proportion to decay activation state toward initial values at start of every trial"}, {Name: "Vm", Doc: "initial membrane potential -- see e_rev.l for the resting potential (typically .3) -- often works better to have a somewhat elevated initial membrane potential relative to that"}, {Name: "Act", Doc: "initial activation value -- typically 0"}, {Name: "Ge", Doc: "baseline level of excitatory conductance (net input) -- Ge is initialized to this value, and it is added in as a constant background level of excitatory input -- captures all the other inputs not represented in the model, and intrinsic excitability, etc"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.DtParams", IDName: "dt-params", Doc: "DtParams are time and rate constants for temporal derivatives in Leabra (Vm, net input)", Fields: []types.Field{{Name: "Integ", Doc: "overall rate constant for numerical integration, for all equations at the unit level -- all time constants are specified in millisecond units, with one cycle = 1 msec -- if you instead want to make one cycle = 2 msec, you can do this globally by setting this integ value to 2 (etc).  However, stability issues will likely arise if you go too high.  For improved numerical stability, you may even need to reduce this value to 0.5 or possibly even lower (typically however this is not necessary).  MUST also coordinate this with network.time_inc variable to ensure that global network.time reflects simulated time accurately"}, {Name: "VmTau", Doc: "membrane potential and rate-code activation time constant in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life) -- reflects the capacitance of the neuron in principle -- biological default for AdEx spiking model C = 281 pF = 2.81 normalized -- for rate-code activation, this also determines how fast to integrate computed activation values over time"}, {Name: "GTau", Doc: "time constant for integrating synaptic conductances, in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life) -- this is important for damping oscillations -- generally reflects time constants associated with synaptic channels which are not modeled in the most abstract rate code models (set to 1 for detailed spiking models with more realistic synaptic currents) -- larger values (e.g., 3) can be important for models with higher conductances that otherwise might be more prone to oscillation."}, {Name: "AvgTau", Doc: "for integrating activation average (ActAvg), time constant in trials (roughly, how long it takes for value to change significantly) -- used mostly for visualization and tracking *hog* units"}, {Name: "VmDt", Doc: "nominal rate = Integ / tau"}, {Name: "GDt", Doc: "rate = Integ / tau"}, {Name: "AvgDt", Doc: "rate = 1 / tau"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActNoiseType", IDName: "act-noise-type", Doc: "ActNoiseType are different types / locations of random noise for activations"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActNoiseParams", IDName: "act-noise-params", Doc: "ActNoiseParams contains parameters for activation-level noise", Embeds: []types.Field{{Name: "RandParams"}}, Fields: []types.Field{{Name: "Type", Doc: "where and how to add processing noise"}, {Name: "Fixed", Doc: "keep the same noise value over the entire alpha cycle -- prevents noise from being washed out and produces a stable effect that can be better used for learning -- this is strongly recommended for most learning situations"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ClampParams", IDName: "clamp-params", Doc: "ClampParams are for specifying how external inputs are clamped onto network activation values", Fields: []types.Field{{Name: "Hard", Doc: "whether to hard clamp inputs where activation is directly set to external input value (Act = Ext) or do soft clamping where Ext is added into Ge excitatory current (Ge += Gain * Ext)"}, {Name: "Range", Doc: "range of external input activation values allowed -- Max is .95 by default due to saturating nature of rate code activation function"}, {Name: "Gain", Doc: "soft clamp gain factor (Ge += Gain * Ext)"}, {Name: "Avg", Doc: "compute soft clamp as the average of current and target netins, not the sum -- prevents some of the main effect problems associated with adding external inputs"}, {Name: "AvgGain", Doc: "gain factor for averaging the Ge -- clamp value Ext contributes with AvgGain and current Ge as (1-AvgGain)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.WtInitParams", IDName: "wt-init-params", Doc: "WtInitParams are weight initialization parameters -- basically the\nrandom distribution parameters but also Symmetry flag", Embeds: []types.Field{{Name: "RandParams"}}, Fields: []types.Field{{Name: "Sym", Doc: "symmetrize the weight values with those in reciprocal pathway -- typically true for bidirectional excitatory connections"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.WtScaleParams", IDName: "wt-scale-params", Doc: "/ WtScaleParams are weight scaling parameters: modulates overall strength of pathway,\nusing both absolute and relative factors", Fields: []types.Field{{Name: "Abs", Doc: "absolute scaling, which is not subject to normalization: directly multiplies weight values"}, {Name: "Rel", Doc: "relative scaling that shifts balance between different pathways -- this is subject to normalization across all other pathways into unit"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Context", IDName: "context", Doc: "leabra.Context contains all the timing state and parameter information for running a model", Fields: []types.Field{{Name: "Time", Doc: "accumulated amount of time the network has been running,\nin simulation-time (not real world time), in seconds."}, {Name: "Cycle", Doc: "cycle counter: number of iterations of activation updating\n(settling) on the current alpha-cycle (100 msec / 10 Hz) trial.\nThis counts time sequentially through the entire trial,\ntypically from 0 to 99 cycles."}, {Name: "CycleTot", Doc: "total cycle count. this increments continuously from whenever\nit was last reset, typically this is number of milliseconds\nin simulation time."}, {Name: "Quarter", Doc: "current gamma-frequency (25 msec / 40 Hz) quarter of alpha-cycle\n(100 msec / 10 Hz) trial being processed.\nDue to 0-based indexing, the first quarter is 0, second is 1, etc.\nThe plus phase final quarter is 3."}, {Name: "PlusPhase", Doc: "true if this is the plus phase (final quarter = 3), else minus phase."}, {Name: "TimePerCyc", Doc: "amount of time to increment per cycle."}, {Name: "CycPerQtr", Doc: "number of cycles per quarter to run: 25 = standard 100 msec alpha-cycle."}, {Name: "Mode", Doc: "current evaluation mode, e.g., Train, Test, etc"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Quarters", IDName: "quarters", Doc: "Quarters are the different alpha trial quarters, as a bitflag,\nfor use in relevant timing parameters where quarters need to be specified.\nThe Q1..4 defined values are integer *bit positions* -- use Set, Has etc methods\nto set bits from these bit positions."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.BurstParams", IDName: "burst-params", Doc: "BurstParams determine how the 5IB Burst activation is computed from\nstandard Act activation values in SuperLayer. It is thresholded.", Fields: []types.Field{{Name: "BurstQtr", Doc: "Quarter(s) when bursting occurs -- typically Q4 but can also be Q2 and Q4 for beta-frequency updating.  Note: this is a bitflag and must be accessed using its Set / Has etc routines, 32 bit versions."}, {Name: "ThrRel", Doc: "Relative component of threshold on superficial activation value, below which it does not drive Burst (and above which, Burst = Act).  This is the distance between the average and maximum activation values within layer (e.g., 0 = average, 1 = max).  Overall effective threshold is MAX of relative and absolute thresholds."}, {Name: "ThrAbs", Doc: "Absolute component of threshold on superficial activation value, below which it does not drive Burst (and above which, Burst = Act).  Overall effective threshold is MAX of relative and absolute thresholds."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Driver", IDName: "driver", Doc: "Driver describes the source of driver inputs from cortex into Pulvinar.", Fields: []types.Field{{Name: "Driver", Doc: "driver layer"}, {Name: "Off", Doc: "offset into Pulvinar pool"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Drivers", IDName: "drivers", Doc: "Drivers are a list of drivers"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PulvinarParams", IDName: "pulvinar-params", Doc: "PulvinarParams provides parameters for how the plus-phase (outcome) state\nof thalamic relay cell (e.g., Pulvinar) neurons is computed from the\ncorresponding driver neuron Burst activation.", Fields: []types.Field{{Name: "DriversOff", Doc: "Turn off the driver inputs, in which case this layer behaves like a standard layer"}, {Name: "BurstQtr", Doc: "Quarter(s) when bursting occurs -- typically Q4 but can also be Q2 and Q4 for beta-frequency updating.  Note: this is a bitflag and must be accessed using its Set / Has etc routines"}, {Name: "DriveScale", Doc: "multiplier on driver input strength, multiplies activation of driver layer"}, {Name: "MaxInhib", Doc: "Level of Max driver layer activation at which the predictive non-burst inputs are fully inhibited.  Computationally, it is essential that driver inputs inhibit effect of predictive non-driver (CTLayer) inputs, so that the plus phase is not always just the minus phase plus something extra (the error will never go to zero then).  When max driver act input exceeds this value, predictive non-driver inputs are fully suppressed.  If there is only weak burst input however, then the predictive inputs remain and this critically prevents the network from learning to turn activation off, which is difficult and severely degrades learning."}, {Name: "NoTopo", Doc: "Do not treat the pools in this layer as topographically organized relative to driver inputs -- all drivers compress down to give same input to all pools"}, {Name: "AvgMix", Doc: "proportion of average across driver pools that is combined with Max to provide some graded tie-breaker signal -- especially important for large pool downsampling, e.g., when doing NoTopo"}, {Name: "Binarize", Doc: "Apply threshold to driver burst input for computing plus-phase activations -- above BinThr, then Act = BinOn, below = BinOff.  This is beneficial for layers with weaker graded activations, such as V1 or other perceptual inputs."}, {Name: "BinThr", Doc: "Threshold for binarizing in terms of sending Burst activation"}, {Name: "BinOn", Doc: "Resulting driver Ge value for units above threshold -- lower value around 0.3 or so seems best (DriveScale is NOT applied -- generally same range as that)."}, {Name: "BinOff", Doc: "Resulting driver Ge value for units below threshold -- typically 0."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.CHLParams", IDName: "chl-params", Doc: "Contrastive Hebbian Learning (CHL) parameters", Fields: []types.Field{{Name: "On", Doc: "if true, use CHL learning instead of standard XCAL learning -- allows easy exploration of CHL vs. XCAL"}, {Name: "Hebb", Doc: "amount of hebbian learning (should be relatively small, can be effective at .0001)"}, {Name: "Err", Doc: "amount of error driven learning, automatically computed to be 1-Hebb"}, {Name: "MinusQ1", Doc: "if true, use ActQ1 as the minus phase -- otherwise ActM"}, {Name: "SAvgCor", Doc: "proportion of correction to apply to sending average activation for hebbian learning component (0=none, 1=all, .5=half, etc)"}, {Name: "SAvgThr", Doc: "threshold of sending average activation below which learning does not occur (prevents learning when there is no input)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.InhibParams", IDName: "inhib-params", Doc: "leabra.InhibParams contains all the inhibition computation params and functions for basic Leabra\nThis is included in leabra.Layer to support computation.\nThis also includes other misc layer-level params such as running-average activation in the layer\nwhich is used for netinput rescaling and potentially for adapting inhibition over time", Fields: []types.Field{{Name: "Layer", Doc: "inhibition across the entire layer"}, {Name: "Pool", Doc: "inhibition across sub-pools of units, for layers with 4D shape"}, {Name: "Self", Doc: "neuron self-inhibition parameters -- can be beneficial for producing more graded, linear response -- not typically used in cortical networks"}, {Name: "ActAvg", Doc: "running-average activation computation values -- for overall estimates of layer activation levels, used in netinput scaling"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.SelfInhibParams", IDName: "self-inhib-params", Doc: "SelfInhibParams defines parameters for Neuron self-inhibition -- activation of the neuron directly feeds back\nto produce a proportional additional contribution to Gi", Fields: []types.Field{{Name: "On", Doc: "enable neuron self-inhibition"}, {Name: "Gi", Doc: "strength of individual neuron self feedback inhibition -- can produce proportional activation behavior in individual units for specialized cases (e.g., scalar val or BG units), but not so good for typical hidden layers"}, {Name: "Tau", Doc: "time constant in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life) for integrating unit self feedback inhibitory values -- prevents oscillations that otherwise occur -- relatively rapid 1.4 typically works, but may need to go longer if oscillations are a problem"}, {Name: "Dt", Doc: "rate = 1 / tau"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActAvgParams", IDName: "act-avg-params", Doc: "ActAvgParams represents expected average activity levels in the layer.\nUsed for computing running-average computation that is then used for netinput scaling.\nAlso specifies time constant for updating average\nand for the target value for adapting inhibition in inhib_adapt.", Fields: []types.Field{{Name: "Init", Doc: "initial estimated average activity level in the layer (see also UseFirst option -- if that is off then it is used as a starting point for running average actual activity level, ActMAvg and ActPAvg) -- ActPAvg is used primarily for automatic netinput scaling, to balance out layers that have different activity levels -- thus it is important that init be relatively accurate -- good idea to update from recorded ActPAvg levels"}, {Name: "Fixed", Doc: "if true, then the Init value is used as a constant for ActPAvgEff (the effective value used for netinput rescaling), instead of using the actual running average activation"}, {Name: "UseExtAct", Doc: "if true, then use the activation level computed from the external inputs to this layer (avg of targ or ext unit vars) -- this will only be applied to layers with Input or Target / Compare layer types, and falls back on the targ_init value if external inputs are not available or have a zero average -- implies fixed behavior"}, {Name: "UseFirst", Doc: "use the first actual average value to override targ_init value -- actual value is likely to be a better estimate than our guess"}, {Name: "Tau", Doc: "time constant in trials for integrating time-average values at the layer level -- used for computing Pool.ActAvg.ActsMAvg, ActsPAvg"}, {Name: "Adjust", Doc: "adjustment multiplier on the computed ActPAvg value that is used to compute ActPAvgEff, which is actually used for netinput rescaling -- if based on connectivity patterns or other factors the actual running-average value is resulting in netinputs that are too high or low, then this can be used to adjust the effective average activity value -- reducing the average activity with a factor < 1 will increase netinput scaling (stronger net inputs from layers that receive from this layer), and vice-versa for increasing (decreases net inputs)"}, {Name: "Dt", Doc: "rate = 1 / tau"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Layer", IDName: "layer", Doc: "Layer implements the Leabra algorithm at the layer level,\nmanaging neurons and pathways.", Embeds: []types.Field{{Name: "LayerBase"}}, Fields: []types.Field{{Name: "Network", Doc: "our parent network, in case we need to use it to\nfind other layers etc; set when added by network."}, {Name: "Type", Doc: "type of layer."}, {Name: "RecvPaths", Doc: "list of receiving pathways into this layer from other layers."}, {Name: "SendPaths", Doc: "list of sending pathways from this layer to other layers."}, {Name: "Act", Doc: "Activation parameters and methods for computing activations."}, {Name: "Inhib", Doc: "Inhibition parameters and methods for computing layer-level inhibition."}, {Name: "Learn", Doc: "Learning parameters and methods that operate at the neuron level."}, {Name: "Burst", Doc: "Burst has parameters for computing Burst from act, in Superficial layers\n(but also needed in Deep layers for deep self connections)."}, {Name: "Pulvinar", Doc: "Pulvinar has parameters for computing Pulvinar plus-phase (outcome)\nactivations based on Burst activation from corresponding driver neuron."}, {Name: "Drivers", Doc: "Drivers are names of SuperLayer(s) that sends 5IB Burst driver\ninputs to this layer."}, {Name: "RW", Doc: "RW are Rescorla-Wagner RL learning parameters."}, {Name: "TD", Doc: "TD are Temporal Differences RL learning parameters."}, {Name: "Matrix", Doc: "Matrix BG gating parameters"}, {Name: "PBWM", Doc: "PBWM has general PBWM parameters, including the shape\nof overall Maint + Out gating system that this layer is part of."}, {Name: "GPiGate", Doc: "GPiGate are gating parameters determining threshold for gating etc."}, {Name: "CIN", Doc: "CIN cholinergic interneuron parameters."}, {Name: "PFCGate", Doc: "PFC Gating parameters"}, {Name: "PFCMaint", Doc: "PFC Maintenance parameters"}, {Name: "PFCDyns", Doc: "PFCDyns dynamic behavior parameters -- provides deterministic control over PFC maintenance dynamics -- the rows of PFC units (along Y axis) behave according to corresponding index of Dyns (inner loop is Super Y axis, outer is Dyn types) -- ensure Y dim has even multiple of len(Dyns)"}, {Name: "Neurons", Doc: "slice of neurons for this layer, as a flat list of len = Shape.Len().\nMust iterate over index and use pointer to modify values."}, {Name: "Pools", Doc: "inhibition and other pooled, aggregate state variables.\nflat list has at least of 1 for layer, and one for each sub-pool\nif shape supports that (4D).\nMust iterate over index and use pointer to modify values."}, {Name: "CosDiff", Doc: "cosine difference between ActM, ActP stats."}, {Name: "NeuroMod", Doc: "NeuroMod is the neuromodulatory neurotransmitter state for this layer."}, {Name: "SendTo", Doc: "SendTo is a list of layers that this layer sends special signals to,\nwhich could be dopamine, gating signals, depending on the layer type."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.LayerTypes", IDName: "layer-types", Doc: "LayerTypes enumerates all the different types of layers,\nfor the different algorithm types supported.\nClass parameter styles automatically key off of these types."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.LearnNeurParams", IDName: "learn-neur-params", Doc: "leabra.LearnNeurParams manages learning-related parameters at the neuron-level.\nThis is mainly the running average activations that drive learning.", Fields: []types.Field{{Name: "ActAvg", Doc: "parameters for computing running average activations that drive learning"}, {Name: "AvgL", Doc: "parameters for computing AvgL long-term running average"}, {Name: "CosDiff", Doc: "parameters for computing cosine diff between minus and plus phase"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.LearnSynParams", IDName: "learn-syn-params", Doc: "leabra.LearnSynParams manages learning-related parameters at the synapse-level.", Fields: []types.Field{{Name: "Learn", Doc: "enable learning for this pathway"}, {Name: "Lrate", Doc: "current effective learning rate (multiplies DWt values, determining rate of change of weights)"}, {Name: "LrateInit", Doc: "initial learning rate -- this is set from Lrate in UpdateParams, which is called when Params are updated, and used in LrateMult to compute a new learning rate for learning rate schedules."}, {Name: "XCal", Doc: "parameters for the XCal learning rule"}, {Name: "WtSig", Doc: "parameters for the sigmoidal contrast weight enhancement"}, {Name: "Norm", Doc: "parameters for normalizing weight changes by abs max dwt"}, {Name: "Momentum", Doc: "parameters for momentum across weight changes"}, {Name: "WtBal", Doc: "parameters for balancing strength of weight increases vs. decreases"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.LrnActAvgParams", IDName: "lrn-act-avg-params", Doc: "LrnActAvgParams has rate constants for averaging over activations at different time scales,\nto produce the running average activation values that then drive learning in the XCAL learning rules", Fields: []types.Field{{Name: "SSTau", Doc: "time constant in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life), for continuously updating the super-short time-scale avg_ss value -- this is provides a pre-integration step before integrating into the avg_s short time scale -- it is particularly important for spiking -- in general 4 is the largest value without starting to impair learning, but a value of 7 can be combined with m_in_s = 0 with somewhat worse results"}, {Name: "STau", Doc: "time constant in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life), for continuously updating the short time-scale avg_s value from the super-short avg_ss value (cascade mode) -- avg_s represents the plus phase learning signal that reflects the most recent past information"}, {Name: "MTau", Doc: "time constant in cycles, which should be milliseconds typically (roughly, how long it takes for value to change significantly -- 1.4x the half-life), for continuously updating the medium time-scale avg_m value from the short avg_s value (cascade mode) -- avg_m represents the minus phase learning signal that reflects the expectation representation prior to experiencing the outcome (in addition to the outcome) -- the default value of 10 generally cannot be exceeded without impairing learning"}, {Name: "LrnM", Doc: "how much of the medium term average activation to mix in with the short (plus phase) to compute the Neuron AvgSLrn variable that is used for the unit's short-term average in learning. This is important to ensure that when unit turns off in plus phase (short time scale), enough medium-phase trace remains so that learning signal doesn't just go all the way to 0, at which point no learning would take place -- typically need faster time constant for updating S such that this trace of the M signal is lost -- can set SSTau=7 and set this to 0 but learning is generally somewhat worse"}, {Name: "Init", Doc: "initial value for average"}, {Name: "SSDt", Doc: "rate = 1 / tau"}, {Name: "SDt", Doc: "rate = 1 / tau"}, {Name: "MDt", Doc: "rate = 1 / tau"}, {Name: "LrnS", Doc: "1-LrnM"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.AvgLParams", IDName: "avg-l-params", Doc: "AvgLParams are parameters for computing the long-term floating average value, AvgL\nwhich is used for driving BCM-style hebbian learning in XCAL -- this form of learning\nincreases contrast of weights and generally decreases overall activity of neuron,\nto prevent \"hog\" units -- it is computed as a running average of the (gain multiplied)\nmedium-time-scale average activation at the end of the alpha-cycle.\nAlso computes an adaptive amount of BCM learning, AvgLLrn, based on AvgL.", Fields: []types.Field{{Name: "Init", Doc: "initial AvgL value at start of training"}, {Name: "Gain", Doc: "gain multiplier on activation used in computing the running average AvgL value that is the key floating threshold in the BCM Hebbian learning rule -- when using the DELTA_FF_FB learning rule, it should generally be 2x what it was before with the old XCAL_CHL rule, i.e., default of 5 instead of 2.5 -- it is a good idea to experiment with this parameter a bit -- the default is on the high-side, so typically reducing a bit from initial default is a good direction"}, {Name: "Min", Doc: "miniumum AvgL value -- running average cannot go lower than this value even when it otherwise would due to inactivity -- default value is generally good and typically does not need to be changed"}, {Name: "Tau", Doc: "time constant for updating the running average AvgL -- AvgL moves toward gain*act with this time constant on every alpha-cycle - longer time constants can also work fine, but the default of 10 allows for quicker reaction to beneficial weight changes"}, {Name: "LrnMax", Doc: "maximum AvgLLrn value, which is amount of learning driven by AvgL factor -- when AvgL is at its maximum value (i.e., gain, as act does not exceed 1), then AvgLLrn will be at this maximum value -- by default, strong amounts of this homeostatic Hebbian form of learning can be used when the receiving unit is highly active -- this will then tend to bring down the average activity of units -- the default of 0.5, in combination with the err_mod flag, works well for most models -- use around 0.0004 for a single fixed value (with err_mod flag off)"}, {Name: "LrnMin", Doc: "miniumum AvgLLrn value (amount of learning driven by AvgL factor) -- if AvgL is at its minimum value, then AvgLLrn will be at this minimum value -- neurons that are not overly active may not need to increase the contrast of their weights as much -- use around 0.0004 for a single fixed value (with err_mod flag off)"}, {Name: "ErrMod", Doc: "modulate amount learning by normalized level of error within layer"}, {Name: "ModMin", Doc: "minimum modulation value for ErrMod-- ensures a minimum amount of self-organizing learning even for network / layers that have a very small level of error signal"}, {Name: "Dt", Doc: "rate = 1 / tau"}, {Name: "LrnFact", Doc: "(LrnMax - LrnMin) / (Gain - Min)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.CosDiffParams", IDName: "cos-diff-params", Doc: "CosDiffParams specify how to integrate cosine of difference between plus and minus phase activations\nUsed to modulate amount of hebbian learning, and overall learning rate.", Fields: []types.Field{{Name: "Tau", Doc: "time constant in alpha-cycles (roughly how long significant change takes, 1.4 x half-life) for computing running average CosDiff value for the layer, CosDiffAvg = cosine difference between ActM and ActP -- this is an important statistic for how much phase-based difference there is between phases in this layer -- it is used in standard X_COS_DIFF modulation of l_mix in LeabraConSpec, and for modulating learning rate as a function of predictability in the DeepLeabra predictive auto-encoder learning -- running average variance also computed with this: cos_diff_var"}, {Name: "Dt", Doc: "rate constant = 1 / Tau"}, {Name: "DtC", Doc: "complement of rate constant = 1 - Dt"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.CosDiffStats", IDName: "cos-diff-stats", Doc: "CosDiffStats holds cosine-difference statistics at the layer level", Fields: []types.Field{{Name: "Cos", Doc: "cosine (normalized dot product) activation difference between ActP and ActM on this alpha-cycle for this layer -- computed by CosDiffFromActs at end of QuarterFinal for quarter = 3"}, {Name: "Avg", Doc: "running average of cosine (normalized dot product) difference between ActP and ActM -- computed with CosDiff.Tau time constant in QuarterFinal, and used for modulating BCM Hebbian learning (see AvgLrn) and overall learning rate"}, {Name: "Var", Doc: "running variance of cosine (normalized dot product) difference between ActP and ActM -- computed with CosDiff.Tau time constant in QuarterFinal, used for modulating overall learning rate"}, {Name: "AvgLrn", Doc: "1 - Avg and 0 for non-Hidden layers"}, {Name: "ModAvgLLrn", Doc: "1 - AvgLrn and 0 for non-Hidden layers -- this is the value of Avg used for AvgLParams ErrMod modulation of the AvgLLrn factor if enabled"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.XCalParams", IDName: "x-cal-params", Doc: "XCalParams are parameters for temporally eXtended Contrastive Attractor Learning function (XCAL)\nwhich is the standard learning equation for leabra .", Fields: []types.Field{{Name: "MLrn", Doc: "multiplier on learning based on the medium-term floating average threshold which produces error-driven learning -- this is typically 1 when error-driven learning is being used, and 0 when pure Hebbian learning is used. The long-term floating average threshold is provided by the receiving unit"}, {Name: "SetLLrn", Doc: "if true, set a fixed AvgLLrn weighting factor that determines how much of the long-term floating average threshold (i.e., BCM, Hebbian) component of learning is used -- this is useful for setting a fully Hebbian learning connection, e.g., by setting MLrn = 0 and LLrn = 1. If false, then the receiving unit's AvgLLrn factor is used, which dynamically modulates the amount of the long-term component as a function of how active overall it is"}, {Name: "LLrn", Doc: "fixed l_lrn weighting factor that determines how much of the long-term floating average threshold (i.e., BCM, Hebbian) component of learning is used -- this is useful for setting a fully Hebbian learning connection, e.g., by setting MLrn = 0 and LLrn = 1."}, {Name: "DRev", Doc: "proportional point within LTD range where magnitude reverses to go back down to zero at zero -- err-driven svm component does better with smaller values, and BCM-like mvl component does better with larger values -- 0.1 is a compromise"}, {Name: "DThr", Doc: "minimum LTD threshold value below which no weight change occurs -- this is now *relative* to the threshold"}, {Name: "LrnThr", Doc: "xcal learning threshold -- don't learn when sending unit activation is below this value in both phases -- due to the nature of the learning function being 0 when the sr coproduct is 0, it should not affect learning in any substantial way -- nonstandard learning algorithms that have different properties should ignore it"}, {Name: "DRevRatio", Doc: "-(1-DRev)/DRev -- multiplication factor in learning rule -- builds in the minus sign!"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.WtSigParams", IDName: "wt-sig-params", Doc: "WtSigParams are sigmoidal weight contrast enhancement function parameters", Fields: []types.Field{{Name: "Gain", Doc: "gain (contrast, sharpness) of the weight contrast function (1 = linear)"}, {Name: "Off", Doc: "offset of the function (1=centered at .5, >1=higher, <1=lower) -- 1 is standard for XCAL"}, {Name: "SoftBound", Doc: "apply exponential soft bounding to the weight changes"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.DWtNormParams", IDName: "d-wt-norm-params", Doc: "DWtNormParams are weight change (dwt) normalization parameters, using MAX(ABS(dwt)) aggregated over\nSending connections in a given pathway for a given unit.\nSlowly decays and instantly resets to any current max(abs)\nServes as an estimate of the variance in the weight changes, assuming zero net mean overall.", Fields: []types.Field{{Name: "On", Doc: "whether to use dwt normalization, only on error-driven dwt component, based on pathway-level max_avg value -- slowly decays and instantly resets to any current max"}, {Name: "DecayTau", Doc: "time constant for decay of dwnorm factor -- generally should be long-ish, between 1000-10000 -- integration rate factor is 1/tau"}, {Name: "NormMin", Doc: "minimum effective value of the normalization factor -- provides a lower bound to how much normalization can be applied"}, {Name: "LrComp", Doc: "overall learning rate multiplier to compensate for changes due to use of normalization -- allows for a common master learning rate to be used between different conditions -- 0.1 for synapse-level, maybe higher for other levels"}, {Name: "Stats", Doc: "record the avg, max values of err, bcm hebbian, and overall dwt change per con group and per pathway"}, {Name: "DecayDt", Doc: "rate constant of decay = 1 / decay_tau"}, {Name: "DecayDtC", Doc: "complement rate constant of decay = 1 - (1 / decay_tau)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.MomentumParams", IDName: "momentum-params", Doc: "MomentumParams implements standard simple momentum -- accentuates consistent directions of weight change and\ncancels out dithering -- biologically captures slower timecourse of longer-term plasticity mechanisms.", Fields: []types.Field{{Name: "On", Doc: "whether to use standard simple momentum"}, {Name: "MTau", Doc: "time constant factor for integration of momentum -- 1/tau is dt (e.g., .1), and 1-1/tau (e.g., .95 or .9) is traditional momentum time-integration factor"}, {Name: "LrComp", Doc: "overall learning rate multiplier to compensate for changes due to JUST momentum without normalization -- allows for a common master learning rate to be used between different conditions -- generally should use .1 to compensate for just momentum itself"}, {Name: "MDt", Doc: "rate constant of momentum integration = 1 / m_tau"}, {Name: "MDtC", Doc: "complement rate constant of momentum integration = 1 - (1 / m_tau)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.WtBalParams", IDName: "wt-bal-params", Doc: "WtBalParams are weight balance soft renormalization params:\nmaintains overall weight balance by progressively penalizing weight increases as a function of\nhow strong the weights are overall (subject to thresholding) and long time-averaged activation.\nPlugs into soft bounding function.", Fields: []types.Field{{Name: "On", Doc: "perform weight balance soft normalization?  if so, maintains overall weight balance across units by progressively penalizing weight increases as a function of amount of averaged receiver weight above a high threshold (hi_thr) and long time-average activation above an act_thr -- this is generally very beneficial for larger models where hog units are a problem, but not as much for smaller models where the additional constraints are not beneficial -- uses a sigmoidal function: WbInc = 1 / (1 + HiGain*(WbAvg - HiThr) + ActGain * (nrn.ActAvg - ActThr)))"}, {Name: "Targs", Doc: "apply soft bounding to target layers -- appears to be beneficial but still testing"}, {Name: "AvgThr", Doc: "threshold on weight value for inclusion into the weight average that is then subject to the further HiThr threshold for then driving a change in weight balance -- this AvgThr allows only stronger weights to contribute so that weakening of lower weights does not dilute sensitivity to number and strength of strong weights"}, {Name: "HiThr", Doc: "high threshold on weight average (subject to AvgThr) before it drives changes in weight increase vs. decrease factors"}, {Name: "HiGain", Doc: "gain multiplier applied to above-HiThr thresholded weight averages -- higher values turn weight increases down more rapidly as the weights become more imbalanced"}, {Name: "LoThr", Doc: "low threshold on weight average (subject to AvgThr) before it drives changes in weight increase vs. decrease factors"}, {Name: "LoGain", Doc: "gain multiplier applied to below-lo_thr thresholded weight averages -- higher values turn weight increases up more rapidly as the weights become more imbalanced -- generally beneficial but sometimes not -- worth experimenting with either 6 or 0"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Network", IDName: "network", Doc: "leabra.Network implements the Leabra algorithm, managing the Layers.", Embeds: []types.Field{{Name: "NetworkBase"}}, Fields: []types.Field{{Name: "Layers", Doc: "list of layers"}, {Name: "NThreads", Doc: "number of parallel threads (go routines) to use."}, {Name: "WtBalInterval", Doc: "how frequently to update the weight balance average\nweight factor -- relatively expensive."}, {Name: "WtBalCtr", Doc: "counter for how long it has been since last WtBal."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.LayerNames", IDName: "layer-names", Doc: "LayerNames is a list of layer names, with methods to add and validate."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.NeuroMod", IDName: "neuro-mod", Doc: "NeuroMod are the neuromodulatory neurotransmitters, at the layer level.", Fields: []types.Field{{Name: "DA", Doc: "DA is dopamine, which primarily modulates learning, and also excitability,\nand reflects the reward prediction error (RPE)."}, {Name: "ACh", Doc: "ACh is acetylcholine, which modulates excitability and also learning,\nand reflects salience, i.e., reward (without discount by prediction) and\nlearned CS onset."}, {Name: "SE", Doc: "SE is serotonin, which is a longer timescale neuromodulator with many\ndifferent effects. Currently not implemented, but here for future expansion."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.DaReceptors", IDName: "da-receptors", Doc: "DaReceptors for D1R and D2R dopamine receptors"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Valences", IDName: "valences", Doc: "Valences for Appetitive and Aversive valence coding"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Neuron", IDName: "neuron", Doc: "leabra.Neuron holds all of the neuron (unit) level variables -- this is the most basic version with\nrate-code only and no optional features at all.\nAll variables accessible via Unit interface must be float32 and start at the top, in contiguous order", Fields: []types.Field{{Name: "Flags", Doc: "bit flags for binary state variables"}, {Name: "SubPool", Doc: "index of the sub-level inhibitory pool that this neuron is in (only for 4D shapes, the pool (unit-group / hypercolumn) structure level) -- indicies start at 1 -- 0 is layer-level pool (is 0 if no sub-pools)."}, {Name: "Act", Doc: "rate-coded activation value reflecting final output of neuron communicated to other neurons, typically in range 0-1.  This value includes adaptation and synaptic depression / facilitation effects which produce temporal contrast (see ActLrn for version without this).  For rate-code activation, this is noisy-x-over-x-plus-one (NXX1) function; for discrete spiking it is computed from the inverse of the inter-spike interval (ISI), and Spike reflects the discrete spikes."}, {Name: "Ge", Doc: "total excitatory synaptic conductance -- the net excitatory input to the neuron -- does *not* include Gbar.E"}, {Name: "Gi", Doc: "total inhibitory synaptic conductance -- the net inhibitory input to the neuron -- does *not* include Gbar.I"}, {Name: "Gk", Doc: "total potassium conductance, typically reflecting sodium-gated potassium currents involved in adaptation effects -- does *not* include Gbar.K"}, {Name: "Inet", Doc: "net current produced by all channels -- drives update of Vm"}, {Name: "Vm", Doc: "membrane potential -- integrates Inet current over time"}, {Name: "Noise", Doc: "noise value added to unit (ActNoiseParams determines distribution, and when / where it is added)"}, {Name: "Spike", Doc: "whether neuron has spiked or not (0 or 1), for discrete spiking neurons."}, {Name: "Targ", Doc: "target value: drives learning to produce this activation value"}, {Name: "Ext", Doc: "external input: drives activation of unit from outside influences (e.g., sensory input)"}, {Name: "AvgSS", Doc: "super-short time-scale average of ActLrn activation -- provides the lowest-level time integration -- for spiking this integrates over spikes before subsequent averaging, and it is also useful for rate-code to provide a longer time integral overall"}, {Name: "AvgS", Doc: "short time-scale average of ActLrn activation -- tracks the most recent activation states (integrates over AvgSS values), and represents the plus phase for learning in XCAL algorithms"}, {Name: "AvgM", Doc: "medium time-scale average of ActLrn activation -- integrates over AvgS values, and represents the minus phase for learning in XCAL algorithms"}, {Name: "AvgL", Doc: "long time-scale average of medium-time scale (trial level) activation, used for the BCM-style floating threshold in XCAL"}, {Name: "AvgLLrn", Doc: "how much to learn based on the long-term floating threshold (AvgL) for BCM-style Hebbian learning -- is modulated by level of AvgL itself (stronger Hebbian as average activation goes higher) and optionally the average amount of error experienced in the layer (to retain a common proportionality with the level of error-driven learning across layers)"}, {Name: "AvgSLrn", Doc: "short time-scale activation average that is actually used for learning -- typically includes a small contribution from AvgM in addition to mostly AvgS, as determined by LrnActAvgParams.LrnM -- important to ensure that when unit turns off in plus phase (short time scale), enough medium-phase trace remains so that learning signal doesn't just go all the way to 0, at which point no learning would take place"}, {Name: "ActLrn", Doc: "learning activation value, reflecting *dendritic* activity that is not affected by synaptic depression or adapdation channels which are located near the axon hillock.  This is the what drives the Avg* values that drive learning. Computationally, neurons strongly discount the signals sent to other neurons to provide temporal contrast, but need to learn based on a more stable reflection of their overall inputs in the dendrites."}, {Name: "ActM", Doc: "the activation state at end of third quarter, which is the traditional posterior-cortical minus phase activation"}, {Name: "ActP", Doc: "the activation state at end of fourth quarter, which is the traditional posterior-cortical plus_phase activation"}, {Name: "ActDif", Doc: "ActP - ActM -- difference between plus and minus phase acts -- reflects the individual error gradient for this neuron in standard error-driven learning terms"}, {Name: "ActDel", Doc: "delta activation: change in Act from one cycle to next -- can be useful to track where changes are taking place"}, {Name: "ActQ0", Doc: "the activation state at start of current alpha cycle (same as the state at end of previous cycle)"}, {Name: "ActQ1", Doc: "the activation state at end of first quarter of current alpha cycle"}, {Name: "ActQ2", Doc: "the activation state at end of second quarter of current alpha cycle"}, {Name: "ActAvg", Doc: "average activation (of final plus phase activation state) over long time intervals (time constant = DtPars.AvgTau -- typically 200) -- useful for finding hog units and seeing overall distribution of activation"}, {Name: "Burst", Doc: "5IB bursting activation value, computed by thresholding regular activation"}, {Name: "BurstPrv", Doc: "previous bursting activation -- used for context-based learning"}, {Name: "GiSyn", Doc: "aggregated synaptic inhibition (from Inhib pathways) -- time integral of GiRaw -- this is added with computed FFFB inhibition to get the full inhibition in Gi"}, {Name: "GiSelf", Doc: "total amount of self-inhibition -- time-integrated to avoid oscillations"}, {Name: "ActSent", Doc: "last activation value sent (only send when diff is over threshold)"}, {Name: "GeRaw", Doc: "raw excitatory conductance (net input) received from sending units (send delta's are added to this value)"}, {Name: "GiRaw", Doc: "raw inhibitory conductance (net input) received from sending units (send delta's are added to this value)"}, {Name: "GknaFast", Doc: "conductance of sodium-gated potassium channel (KNa) fast dynamics (M-type) -- produces accommodation / adaptation of firing"}, {Name: "GknaMed", Doc: "conductance of sodium-gated potassium channel (KNa) medium dynamics (Slick) -- produces accommodation / adaptation of firing"}, {Name: "GknaSlow", Doc: "conductance of sodium-gated potassium channel (KNa) slow dynamics (Slack) -- produces accommodation / adaptation of firing"}, {Name: "ISI", Doc: "current inter-spike-interval -- counts up since last spike.  Starts at -1 when initialized."}, {Name: "ISIAvg", Doc: "average inter-spike-interval -- average time interval between spikes.  Starts at -1 when initialized, and goes to -2 after first spike, and is only valid after the second spike post-initialization."}, {Name: "CtxtGe", Doc: "CtxtGe is context (temporally delayed) excitatory conducances."}, {Name: "ActG", Doc: "gating activation -- the activity value when gating occurred in this pool."}, {Name: "DALrn", Doc: "per-neuron effective learning dopamine value -- gain modulated and sign reversed for D2R"}, {Name: "Shunt", Doc: "shunting input received from Patch neurons (in reality flows through SNc DA pathways)"}, {Name: "Maint", Doc: "maintenance value for Deep layers = sending act at time of gating"}, {Name: "MaintGe", Doc: "maintenance excitatory conductance value for Deep layers"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.NeurFlags", IDName: "neur-flags", Doc: "NeurFlags are bit-flags encoding relevant binary state for neurons"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.WtBalRecvPath", IDName: "wt-bal-recv-path", Doc: "WtBalRecvPath are state variables used in computing the WtBal weight balance function\nThere is one of these for each Recv Neuron participating in the pathway.", Fields: []types.Field{{Name: "Avg", Doc: "average of effective weight values that exceed WtBal.AvgThr across given Recv Neuron's connections for given Path"}, {Name: "Fact", Doc: "overall weight balance factor that drives changes in WbInc vs. WbDec via a sigmoidal function -- this is the net strength of weight balance changes"}, {Name: "Inc", Doc: "weight balance increment factor -- extra multiplier to add to weight increases to maintain overall weight balance"}, {Name: "Dec", Doc: "weight balance decrement factor -- extra multiplier to add to weight decreases to maintain overall weight balance"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Path", IDName: "path", Doc: "Path implements the Leabra algorithm at the synaptic level,\nin terms of a pathway connecting two layers.", Embeds: []types.Field{{Name: "PathBase"}}, Fields: []types.Field{{Name: "Send", Doc: "sending layer for this pathway."}, {Name: "Recv", Doc: "receiving layer for this pathway."}, {Name: "Type", Doc: "type of pathway."}, {Name: "WtInit", Doc: "initial random weight distribution"}, {Name: "WtScale", Doc: "weight scaling parameters: modulates overall strength of pathway,\nusing both absolute and relative factors."}, {Name: "Learn", Doc: "synaptic-level learning parameters"}, {Name: "FromSuper", Doc: "For CTCtxtPath if true, this is the pathway from corresponding\nSuperficial layer.  Should be OneToOne path, with Learn.Learn = false,\nWtInit.Var = 0, Mean = 0.8. These defaults are set if FromSuper = true."}, {Name: "CHL", Doc: "CHL are the parameters for CHL learning. if CHL is On then\nWtSig.SoftBound is automatically turned off, as it is incompatible."}, {Name: "Trace", Doc: "special parameters for matrix trace learning"}, {Name: "Syns", Doc: "synaptic state values, ordered by the sending layer\nunits which owns them -- one-to-one with SConIndex array."}, {Name: "GScale", Doc: "scaling factor for integrating synaptic input conductances (G's).\ncomputed in AlphaCycInit, incorporates running-average activity levels."}, {Name: "GInc", Doc: "local per-recv unit increment accumulator for synaptic\nconductance from sending units. goes to either GeRaw or GiRaw\non neuron depending on pathway type."}, {Name: "CtxtGeInc", Doc: "CtxtGeInc is local per-recv unit accumulator for Ctxt excitatory\nconductance from sending units, Not a delta, the full value."}, {Name: "GeRaw", Doc: "per-recv, per-path raw excitatory input, for GPiThalPath."}, {Name: "WbRecv", Doc: "weight balance state variables for this pathway, one per recv neuron."}, {Name: "RConN", Doc: "number of recv connections for each neuron in the receiving layer,\nas a flat list."}, {Name: "RConNAvgMax", Doc: "average and maximum number of recv connections in the receiving layer."}, {Name: "RConIndexSt", Doc: "starting index into ConIndex list for each neuron in\nreceiving layer; list incremented by ConN."}, {Name: "RConIndex", Doc: "index of other neuron on sending side of pathway,\nordered by the receiving layer's order of units as the\nouter loop (each start is in ConIndexSt),\nand then by the sending layer's units within that."}, {Name: "RSynIndex", Doc: "index of synaptic state values for each recv unit x connection,\nfor the receiver pathway which does not own the synapses,\nand instead indexes into sender-ordered list."}, {Name: "SConN", Doc: "number of sending connections for each neuron in the\nsending layer, as a flat list."}, {Name: "SConNAvgMax", Doc: "average and maximum number of sending connections\nin the sending layer."}, {Name: "SConIndexSt", Doc: "starting index into ConIndex list for each neuron in\nsending layer; list incremented by ConN."}, {Name: "SConIndex", Doc: "index of other neuron on receiving side of pathway,\nordered by the sending layer's order of units as the\nouter loop (each start is in ConIndexSt), and then\nby the sending layer's units within that."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PathTypes", IDName: "path-types", Doc: "PathTypes enumerates all the different types of leabra pathways,\nfor the different algorithm types supported.\nClass parameter styles automatically key off of these types."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.MatrixParams", IDName: "matrix-params", Doc: "MatrixParams has parameters for Dorsal Striatum Matrix computation.\nThese are the main Go / NoGo gating units in BG driving updating of PFC WM in PBWM.", Fields: []types.Field{{Name: "LearnQtr", Doc: "Quarter(s) when learning takes place, typically Q2 and Q4, corresponding to the PFC GateQtr. Note: this is a bitflag and must be accessed using bitflag.Set / Has etc routines, 32 bit versions."}, {Name: "PatchShunt", Doc: "how much the patch shunt activation multiplies the dopamine values -- 0 = complete shunting, 1 = no shunting -- should be a factor < 1.0"}, {Name: "ShuntACh", Doc: "also shunt the ACh value driven from CIN units -- this prevents clearing of MSNConSpec traces -- more plausibly the patch units directly interfere with the effects of CIN's rather than through ach, but it is easier to implement with ach shunting here."}, {Name: "OutAChInhib", Doc: "how much does the LACK of ACh from the CIN units drive extra inhibition to output-gating Matrix units -- gi += out_ach_inhib * (1-ach) -- provides a bias for output gating on reward trials -- do NOT apply to NoGo, only Go -- this is a key param -- between 0.1-0.3 usu good -- see how much output gating happening and change accordingly"}, {Name: "BurstGain", Doc: "multiplicative gain factor applied to positive (burst) dopamine signals in computing DALrn effect learning dopamine value based on raw DA that we receive (D2R reversal occurs *after* applying Burst based on sign of raw DA)"}, {Name: "DipGain", Doc: "multiplicative gain factor applied to positive (burst) dopamine signals in computing DALrn effect learning dopamine value based on raw DA that we receive (D2R reversal occurs *after* applying Burst based on sign of raw DA)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.GateTypes", IDName: "gate-types", Doc: "GateTypes for region of striatum"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PBWMParams", IDName: "pbwm-params", Doc: "PBWMParams defines the shape of the outer pool dimensions of gating layers,\norganized into Maint and Out subsets which are arrayed along the X axis\nwith Maint first (to the left) then Out.  Individual layers may only\nrepresent Maint or Out subsets of this overall shape, but all need\nto have this coordinated shape information to be able to share gating\nstate information.  Each layer represents gate state information in\ntheir native geometry -- FullIndex1D provides access from a subset\nto full set.", Fields: []types.Field{{Name: "Type", Doc: "Type of gating layer"}, {Name: "DaR", Doc: "dominant type of dopamine receptor -- D1R for Go pathway, D2R for NoGo"}, {Name: "Y", Doc: "overall shape dimensions for the full set of gating pools,\ne.g., as present in the Matrix and GPiThal levels"}, {Name: "MaintX", Doc: "how many pools in the X dimension are Maint gating pools -- rest are Out"}, {Name: "OutX", Doc: "how many pools in the X dimension are Out gating pools -- comes after Maint"}, {Name: "MaintN", Doc: "For the Matrix layers, this is the number of Maint Pools in X outer\ndimension of 4D shape -- Out gating after that. Note: it is unclear\nhow this relates to MaintX, but it is different in SIR model."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.GateState", IDName: "gate-state", Doc: "GateState is gating state values stored in layers that receive thalamic gating signals\nincluding MatrixLayer, PFCLayer, GPiThal layer, etc -- use GateLayer as base layer to include.", Fields: []types.Field{{Name: "Act", Doc: "gating activation value, reflecting thalamic gating layer activation at time of gating (when Now = true) -- will be 0 if gating below threshold for this pool, and prior to first Now for AlphaCycle"}, {Name: "Now", Doc: "gating timing signal -- true if this is the moment when gating takes place"}, {Name: "Cnt", Doc: "unique to each layer -- not copied.  Generally is a counter for interval between gating signals -- starts at -1, goes to 0 at first gating, counts up from there for subsequent gating.  Can be reset back to -1 when gate is reset (e.g., output gating) and counts down from -1 while not gating."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.GPiGateParams", IDName: "g-pi-gate-params", Doc: "GPiGateParams has gating parameters for gating in GPiThal layer, including threshold.", Fields: []types.Field{{Name: "GateQtr", Doc: "GateQtr is the Quarter(s) when gating takes place, typically Q1 and Q3,\nwhich is the quarter prior to the PFC GateQtr when deep layer updating\ntakes place. Note: this is a bitflag and must be accessed using bitflag.\nSet / Has etc routines, 32 bit versions."}, {Name: "Cycle", Doc: "Cycle within Qtr to determine if activation over threshold for gating.\nWe send GateState updates on this cycle either way."}, {Name: "GeGain", Doc: "extra netinput gain factor to compensate for reduction in Ge from subtracting away NoGo -- this is *IN ADDITION* to adding the NoGo factor as an extra gain: Ge = (GeGain + NoGo) * (GoIn - NoGo * NoGoIn)"}, {Name: "NoGo", Doc: "how much to weight NoGo inputs relative to Go inputs (which have an implied weight of 1 -- this also up-scales overall Ge to compensate for subtraction"}, {Name: "Thr", Doc: "threshold for gating, applied to activation -- when any GPiThal unit activation gets above this threshold, it counts as having gated, driving updating of GateState which is broadcast to other layers that use the gating signal"}, {Name: "ThrAct", Doc: "Act value of GPiThal unit reflects gating threshold: if below threshold, it is zeroed -- see ActLrn for underlying non-thresholded activation"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.CINParams", IDName: "cin-params", Doc: "CINParams (cholinergic interneuron) reads reward signals from named source layer(s)\nand sends the Max absolute value of that activity as the positively rectified\nnon-prediction-discounted reward signal computed by CINs, and sent as\nan acetylcholine (ACh) signal.\nTo handle positive-only reward signals, need to include both a reward prediction\nand reward outcome layer.", Fields: []types.Field{{Name: "RewThr", Doc: "RewThr is the threshold on reward values from RewLays,\nto count as a significant reward event, which then drives maximal ACh.\nSet to 0 to disable this nonlinear behavior."}, {Name: "RewLays", Doc: "Reward-representing layer(s) from which this computes ACh as Max absolute value"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PFCGateParams", IDName: "pfc-gate-params", Doc: "PFCGateParams has parameters for PFC gating", Fields: []types.Field{{Name: "GateQtr", Doc: "Quarter(s) that the effect of gating on updating Deep from Super occurs -- this is typically 1 quarter after the GPiThal GateQtr"}, {Name: "OutGate", Doc: "if true, this PFC layer is an output gate layer, which means that it only has transient activation during gating"}, {Name: "OutQ1Only", Doc: "for output gating, only compute gating in first quarter -- do not compute in 3rd quarter -- this is typically true, and GateQtr is typically set to only Q1 as well -- does Burst updating immediately after first quarter gating signal -- allows gating signals time to influence performance within a single trial"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PFCMaintParams", IDName: "pfc-maint-params", Doc: "PFCMaintParams for PFC maintenance functions", Fields: []types.Field{{Name: "UseDyn", Doc: "use fixed dynamics for updating deep_ctxt activations -- defined in dyn_table -- this also preserves the initial gating deep_ctxt value in Maint neuron val (view as Cust1) -- otherwise it is up to the recurrent loops between super and deep for maintenance"}, {Name: "MaintGain", Doc: "multiplier on maint current"}, {Name: "OutClearMaint", Doc: "on output gating, clear corresponding maint pool.  theoretically this should be on, but actually it works better off in most cases.."}, {Name: "Clear", Doc: "how much to clear out (decay) super activations when the stripe itself gates and was previously maintaining something, or for maint pfc stripes, when output go fires and clears."}, {Name: "MaxMaint"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PFCDyn", IDName: "pfc-dyn", Doc: "PFC dynamic behavior element -- defines the dynamic behavior of deep layer PFC units", Fields: []types.Field{{Name: "Init", Doc: "initial value at point when gating starts -- MUST be > 0 when used."}, {Name: "RiseTau", Doc: "time constant for linear rise in maintenance activation (per quarter when deep is updated) -- use integers -- if both rise and decay then rise comes first"}, {Name: "DecayTau", Doc: "time constant for linear decay in maintenance activation (per quarter when deep is updated) -- use integers -- if both rise and decay then rise comes first"}, {Name: "Desc", Doc: "description of this factor"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.PFCDyns", IDName: "pfc-dyns", Doc: "PFCDyns is a slice of dyns. Provides deterministic control over PFC\nmaintenance dynamics -- the rows of PFC units (along Y axis) behave\naccording to corresponding index of Dyns.\nensure layer Y dim has even multiple of len(Dyns)."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.TraceParams", IDName: "trace-params", Doc: "Params for for trace-based learning in the MatrixTracePath", Fields: []types.Field{{Name: "NotGatedLR", Doc: "learning rate for all not-gated stripes, which learn in the opposite direction to the gated stripes, and typically with a slightly lower learning rate -- although there are different learning logics associated with each of these different not-gated cases, in practice the same learning rate for all works best, and is simplest"}, {Name: "GateNoGoPosLR", Doc: "learning rate for gated, NoGo (D2), positive dopamine (weights decrease) -- this is the single most important learning parameter here -- by making this relatively small (but non-zero), an asymmetry in the role of Go vs. NoGo is established, whereby the NoGo pathway focuses largely on punishing and preventing actions associated with negative outcomes, while those assoicated with positive outcomes only very slowly get relief from this NoGo pressure -- this is critical for causing the model to explore other possible actions even when a given action SOMETIMES produces good results -- NoGo demands a very high, consistent level of good outcomes in order to have a net decrease in these avoidance weights.  Note that the gating signal applies to both Go and NoGo MSN's for gated stripes, ensuring learning is about the action that was actually selected (see not_ cases for logic for actions that were close but not taken)"}, {Name: "AChDecay", Doc: "decay driven by receiving unit ACh value, sent by CIN units, for reseting the trace"}, {Name: "Decay", Doc: "multiplier on trace activation for decaying prior traces -- new trace magnitude drives decay of prior trace -- if gating activation is low, then new trace can be low and decay is slow, so increasing this factor causes learning to be more targeted on recent gating changes"}, {Name: "Deriv", Doc: "use the sigmoid derivative factor 2 * act * (1-act) in modulating learning -- otherwise just multiply by msn activation directly -- this is generally beneficial for learning to prevent weights from continuing to increase when activations are already strong (and vice-versa for decreases)"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Pool", IDName: "pool", Doc: "Pool contains computed values for FFFB inhibition, and various other state values for layers\nand pools (unit groups) that can be subject to inhibition, including:\n* average / max stats on Ge and Act that drive inhibition\n* average activity overall that is used for normalizing netin (at layer level)", Fields: []types.Field{{Name: "StIndex", Doc: "starting and ending (exlusive) indexes for the list of neurons in this pool"}, {Name: "EdIndex", Doc: "starting and ending (exlusive) indexes for the list of neurons in this pool"}, {Name: "Inhib", Doc: "FFFB inhibition computed values, including Ge and Act AvgMax which drive inhibition"}, {Name: "ActM", Doc: "minus phase average and max Act activation values, for ActAvg updt"}, {Name: "ActP", Doc: "plus phase average and max Act activation values, for ActAvg updt"}, {Name: "ActAvg", Doc: "running-average activation levels used for netinput scaling and adaptive inhibition"}, {Name: "Gate", Doc: "\tGate is gating state for PBWM layers"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.ActAvg", IDName: "act-avg", Doc: "ActAvg are running-average activation levels used for netinput scaling and adaptive inhibition", Fields: []types.Field{{Name: "ActMAvg", Doc: "running-average minus-phase activity -- used for adapting inhibition -- see ActAvgParams.Tau for time constant etc"}, {Name: "ActPAvg", Doc: "running-average plus-phase activity -- used for synaptic input scaling -- see ActAvgParams.Tau for time constant etc"}, {Name: "ActPAvgEff", Doc: "ActPAvg * ActAvgParams.Adjust -- adjusted effective layer activity directly used in synaptic input scaling"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.RWParams", IDName: "rw-params", Fields: []types.Field{{Name: "PredRange", Doc: "PredRange is the range of predictions that can be represented by the [RWRewPredLayer].\nHaving a truncated range preserves some sensitivity in dopamine at the extremes\nof good or poor performance."}, {Name: "RewLay", Doc: "RewLay is the reward layer name, for [RWDaLayer], from which DA is obtained.\nIf nothing clamped, no dopamine computed."}, {Name: "PredLay", Doc: "PredLay is the name of [RWPredLayer] layer, for [RWDaLayer], that is used for\nsubtracting prediction from the reward value."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.TDParams", IDName: "td-params", Doc: "TDParams are params for TD temporal differences computation.", Fields: []types.Field{{Name: "Discount", Doc: "discount factor -- how much to discount the future prediction from RewPred."}, {Name: "PredLay", Doc: "name of [TDPredLayer] to get reward prediction from."}, {Name: "IntegLay", Doc: "name of [TDIntegLayer] from which this computes the temporal derivative."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/leabra/v2/leabra.Synapse", IDName: "synapse", Doc: "leabra.Synapse holds state for the synaptic connection between neurons", Fields: []types.Field{{Name: "Wt", Doc: "synaptic weight value, sigmoid contrast-enhanced version\nof the linear weight LWt."}, {Name: "LWt", Doc: "linear (underlying) weight value, which learns according\nto the lrate specified in the connection spec.\nThis is converted into the effective weight value, Wt,\nvia sigmoidal contrast enhancement (see WtSigParams)."}, {Name: "DWt", Doc: "change in synaptic weight, driven by learning algorithm."}, {Name: "Norm", Doc: "DWt normalization factor, reset to max of abs value of DWt,\ndecays slowly down over time. Serves as an estimate of variance\nin weight changes over time."}, {Name: "Moment", Doc: "momentum, as time-integrated DWt changes, to accumulate a\nconsistent direction of weight change and cancel out\ndithering contradictory changes."}, {Name: "Scale", Doc: "scaling parameter for this connection: effective weight value\nis scaled by this factor in computing G conductance.\nThis is useful for topographic connectivity patterns e.g.,\nto enforce more distant connections to always be lower in magnitude\nthan closer connections.  Value defaults to 1 (cannot be exactly 0,\notherwise is automatically reset to 1; use a very small number to\napproximate 0). Typically set by using the paths.Pattern Weights()\nvalues where appropriate."}, {Name: "NTr", Doc: "NTr is the new trace, which drives updates to trace value.\nsu * (1-ru_msn) for gated, or su * ru_msn for not-gated (or for non-thalamic cases)."}, {Name: "Tr", Doc: "Tr is the current ongoing trace of activations, which drive learning.\nAdds NTr and clears after learning on current values, and includes both\nthal gated (+ and other nongated, - inputs)."}}})
